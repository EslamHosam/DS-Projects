{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitable App Profiles for the App Store and Google Play Markets\n",
    "Our aim in this project is to find mobile app profiles that are profitable for the App Store and Google Play markets. We're working as data analysts for a company that builds Android and iOS mobile apps, and our job is to enable our team of developers to make data-driven decisions with respect to the kind of apps they build.\n",
    "\n",
    "At our company, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means that our revenue for any given app is mostly influenced by the number of users that use our app. Our goal for this project is to analyze data to help our developers understand what kinds of apps are likely to attract more users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Eslam\\\\Desktop\\\\DQ project\\\\data sets\\\\googleplaystore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b29074318ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcsv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# open google play dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mopened_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\Eslam\\Desktop\\DQ project\\data sets\\googleplaystore.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mread_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Eslam\\\\Desktop\\\\DQ project\\\\data sets\\\\googleplaystore.csv'"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "# open google play dataset\n",
    "opened_file = open('C:\\\\Users\\Eslam\\Desktop\\DQ project\\data sets\\googleplaystore.csv', encoding = \"utf8\" )\n",
    "read_file = reader(opened_file)\n",
    "data = list(read_file)\n",
    "android_header = data[0]\n",
    "android = data[1:]\n",
    "\n",
    "# open app store\n",
    "opened_file = open('C:\\\\Users\\Eslam\\Desktop\\DQ project\\data sets\\AppleStore.csv' , encoding = \"utf8\")\n",
    "read_file = reader(opened_file)\n",
    "data = list(read_file)\n",
    "ios_header = data[0]\n",
    "ios = data[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To make it easier to explore the two data sets, we'll first write a function named explore_data() that we can use repeatedly to explore rows in a more readable way. We'll also add an option for our function to show the number of rows and columns for any data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset , start , end , colm_rows = False):\n",
    "    data_slice = dataset[start : end]\n",
    "    for app in data_slice:\n",
    "        print(app)\n",
    "        print('\\n')\n",
    "    if colm_rows: #it means alawys if True \n",
    "        print(\"number of  rows = \" , len(dataset))\n",
    "        print(\"number of column = \" , len(dataset[0]))\n",
    "\n",
    "ex_ios = explore_data(android , 5 , 10 , True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see that the Google Play data set has 10841 apps and 13 columns. At a quick glance, the columns that might be useful for the purpose of our analysis are 'App', 'Category', 'Reviews', 'Installs', 'Type', 'Price', and 'Genres'.\n",
    "\n",
    "Now let's take a look at the App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ios_header , '\\n')\n",
    "explore_data(ios , 0 , 3 , True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the google play store you find an error in column 10472  the rating is '19' so we should delete this column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android , 10471 , 10473 )\n",
    "print(len(android))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android[10472] , '\\n')\n",
    "#del android[10472] #run it only once \n",
    "print(android[10472])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check duplicates\n",
    "there are two duplicates data in AppStore data set.\n",
    "we are going to show some duplicated data entries of 'Instagram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicates\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name == 'Instagram' or name == 'Twitter':\n",
    "        print(app)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking the number of duplicates on each dataset \n",
    "def check_number_of_duplicates(dataset):\n",
    "    unique_apps = []\n",
    "    duplicate_apps = []\n",
    "    clean_data = []\n",
    "    for app in dataset:\n",
    "        name = app[0]\n",
    "        if name in unique_apps:\n",
    "            duplicate_apps.append(name)\n",
    "        else:\n",
    "            unique_apps.append(name)\n",
    "            clean_data.append(app)\n",
    "    return len(duplicate_apps) , len(clean_data) , len(unique_apps)\n",
    "\n",
    "check_number_of_duplicates(android)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing duplicates\n",
    "in removing duplicates it is like isolating the duplicates and put the clean data seperated \n",
    "so we define two empty lists \n",
    "- one for duplicates \n",
    "- another one for clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to detect duplicate how many rows are duplicted that we should delete\n",
    "duplicat_apps = []\n",
    "unique_apps = []\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicat_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "        \n",
    "print(len(unique_apps) , '' , len(duplicat_apps)) # (10840 - 1181)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting removing the duplicates based on our criteria\n",
    "\n",
    "Now, let's use the reviews_max dictionary to remove the duplicates. For the duplicate cases, we'll only keep the entries with the highest number of reviews. In the code cell below:\n",
    "\n",
    "- We start by initializing two empty lists, android_clean and already_added.\n",
    "- We loop through the android data set, and for every iteration:\n",
    "\n",
    "   - We isolate the name of the app and the number of reviews.\n",
    "   - We add the current row (app) to the android_clean list, and the app name (name) to the already_cleaned list if:\n",
    "     - The number of reviews of the current app matches the number of reviews of that app as described in the reviews_max dictionary; \n",
    "       and\n",
    "       \n",
    "        \n",
    "       -\"\"The name of the app is not already in the already_added list. We need to add this supplementary condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (for example, the Box app has three entries, and the number of reviews is the same). If we just check for reviews_max[name] == n_reviews, we'll still end up with duplicate entries for some apps\"\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    if (name in reviews_max and n_reviews > reviews_max[name]):\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "#the start to isolate the data with the highst values\n",
    "android_clean = []\n",
    "already_added = []\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    if (n_reviews == reviews_max[name]) and (name not in already_added):\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name)\n",
    "print(len(android_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's explore the dataset to be sure that our datat is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android_clean , 5 , 10 , True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing non english apps\n",
    "### part one\n",
    "if we explore the data enough we find some apps contain non english names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ios[814][2])\n",
    "print(ios[6734][2])\n",
    "print('\\n')\n",
    "print(android_clean[4412][0])\n",
    "print(android_clean[7940][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for removing these apps we can make function to check if the name is in english letters domain or not \n",
    "it is simple criteria which we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to understand only\n",
    "def is_english(string):\n",
    "        for char in string:\n",
    "            if ord(char) > 127:\n",
    "                return False\n",
    "        return True\n",
    "is_english('Instagram')\n",
    "\n",
    "def is_english(string):\n",
    "    in_ascii = 0\n",
    "    for char in string:\n",
    "        if ord(char) > 127:\n",
    "            in_ascii += 1\n",
    "            if in_ascii > 3:\n",
    "                return False\n",
    "    return True\n",
    "  \n",
    "            \n",
    "print(is_english('eslam hosam للال'))\n",
    "print(is_english('Docs To Go™ Free Office Suite'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is still not perfect, and very few non-English apps might get past our filter, but this seems good enough at this point in our analysis — we shouldn't spend too much time on optimization at this point.\n",
    "\n",
    "Below, we use the is_english() function to filter out the non-English apps for both data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_english = []\n",
    "ios_english = []\n",
    "#for android\n",
    "for app in android_clean:\n",
    "    name = app[0]\n",
    "    if is_english(name):\n",
    "        android_english.append(app)\n",
    "        \n",
    "#for ios\n",
    "for app in ios:\n",
    "    name = app[2]\n",
    "    if is_english(name):\n",
    "        ios_english.append(app)\n",
    "        \n",
    "explore_data(android_english , 2 , 5 , True)\n",
    "print('\\n')\n",
    "explore_data(ios_english , 2 , 5 , True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating the Free Apps¶\n",
    "As we mentioned in the introduction, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. Our data sets contain both free and non-free apps, and we'll need to isolate only the free apps for our analysis. Below, we isolate the free apps for both our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_final = []\n",
    "ios_final = []\n",
    "\n",
    "for app in android_english:\n",
    "    price = app[7]\n",
    "    if price == '0':\n",
    "        android_final.append(app)\n",
    "        \n",
    "for app in ios_english:\n",
    "    price = app[5]\n",
    "    if price == '0':\n",
    "        ios_final.append(app)\n",
    "\n",
    "explore_data(ios_final , 2 , 4 , True)\n",
    "explore_data(android_final , 2 , 4 , True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We're left with 8864 Android apps and 3222 iOS apps, which should be enough for our analysis.\n",
    "\n",
    "## Most Common Apps by Genre\n",
    "### Part One\n",
    "As we mentioned in the introduction, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "\n",
    "Build a minimal Android version of the app, and add it to Google Play.\n",
    "If the app has a good response from users, we then develop it further.\n",
    "If the app is profitable after six months, we also build an iOS version of the app and add it to the App Store.\n",
    "Because our end goal is to add the app on both the App Store and Google Play, we need to find app profiles that are successful on both markets. For instance, a profile that might work well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "Let's begin the analysis by getting a sense of the most common genres for each market. For this, we'll build a frequency table for the prime_genre column of the App Store data set, and the Genres and Category columns of the Google Play data set.\n",
    "\n",
    "### Part Two\n",
    "We'll build two functions we can use to analyze the frequency tables:\n",
    "\n",
    "One function to generate frequency tables that show percentages\n",
    "Another function that we can use to display the percentages in a descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make frequency table function for any dataset\n",
    "def freq_tables(dataset , index):\n",
    "    table = {}\n",
    "    all_values = 0\n",
    "    for app in dataset:\n",
    "        all_values += 1\n",
    "        column = app[index]\n",
    "        if column in table:\n",
    "            table[column] += 1\n",
    "        else:\n",
    "            table[column] = 1\n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        perceantage = (table[key] / all_values) * 100\n",
    "        table_percentages[key] = perceantage\n",
    "        \n",
    "    return table_percentages \n",
    "\n",
    "# display the values but in decending order so we need to sort and change to list of tubles \n",
    "def display_percentages(dataset , index):\n",
    "    table = freq_tables(dataset , index)\n",
    "    list_of_tubles = []\n",
    "    for value in table:\n",
    "        value_as_tuble = (table[value] , value)\n",
    "        list_of_tubles.append(value_as_tuble)\n",
    "        sorted_list = sorted(list_of_tubles , reverse = True)\n",
    "        \n",
    "    for v in sorted_list:\n",
    "        print(v[1] , \":\" , v[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset , index):\n",
    "    table = {}\n",
    "    values = 0\n",
    "    for app in dataset:\n",
    "        values += 1\n",
    "        col = app[index]\n",
    "        if col in table:\n",
    "            table[col] += 1\n",
    "        else:\n",
    "            table[col] = 1\n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        percentages = (table[key] / values) * 100\n",
    "        table_percentages[key] = percentages\n",
    "        \n",
    "    return table_percentages\n",
    "\n",
    "def display_table(dataset , index):\n",
    "    table = freq_table(dataset , index)\n",
    "    list_of_tubles = []\n",
    "    for key in table:\n",
    "        value_as_tuble = (table[key] , key)\n",
    "        list_of_tubles.append(value_as_tuble)\n",
    "        sorted_list = sorted(list_of_tubles , reverse = True)\n",
    "    \n",
    "    for tuble in sorted_list:\n",
    "        print(tuble[1] , tuble[0])\n",
    "        \n",
    "display_table(android_final , -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_percentages(android_final, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_percentages(android_final , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The difference between the Genres and the Category columns is not crystal clear, but one thing we can notice is that the Genres column is much more granular (it has more categories). We're only looking for the bigger picture at the moment, so we'll only work with the Category column moving forward.\n",
    "\n",
    "Up to this point, we found that the App Store is dominated by apps designed for fun, while Google Play shows a more balanced landscape of both practical and for-fun apps. Now we'd like to get an idea about the kind of apps that have most users.\n",
    "\n",
    "## Most Popular Apps by Genre on the App Store\n",
    "One way to find out what genres are the most popular (have the most users) is to calculate the average number of installs for each app genre. For the Google Play data set, we can find this information in the Installs column, but for the App Store data set this information is missing. As a workaround, we'll take the total number of user ratings as a proxy, which we can find in the rating_count_tot app.\n",
    "\n",
    "Below, we calculate the average number of user ratings per app genre on the App Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genres_ios = freq_table(ios_final, -5)\n",
    "\n",
    "for genre in genres_ios:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for app in ios_final:\n",
    "        genre_app = app[-5]\n",
    "        if genre_app == genre:            \n",
    "            n_ratings = float(app[5])\n",
    "            total += n_ratings\n",
    "            len_genre += 1\n",
    "    avg_n_ratings = total / len_genre\n",
    "    print(genre, ':', avg_n_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
